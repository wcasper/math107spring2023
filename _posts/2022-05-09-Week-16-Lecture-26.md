---
layout: post
---

Notes and highlights from lecture

## Today's Objectives

* Decomposing matrices
* Singular value decomposition

## Factoring matrices

In applications, many numerical methods are based on strategic decomposition of matrices as a product of other matrices with certain nice qualities.
Some important famous examples include
* Diagonalization
* LU decomposition
* Cholesky decomposition
* QR decomposition
* Singular value decomposition

Depending on the application in mind, one decomposition may be more desirable than another.
We will focus here on some decompositions associated with the eigenvectors and eigenvalues of a matrix.



## Diagonalization

Let $$A$$ be an $$n\times n$$ matrix.  A **diagonalization** of $$A$$ is a way of relating the matrix $$A$$ to a diagonal matrix.

**Definition:** An $$m\times n$$ matrix $$D$$ is called **diagonal** if all of the entries away from the main diagonal are zero, ie.

$$D(j,k) = 0\ \text{for all j\neq k}.$$

A **diagonalization** of $$A$$ is a pair of matrices $$P$$ and $$D$$ with $$P$$ an invertible matrix and $$D$$ a diagonal matrix satisfying

$$A = PDP^{-1}.$$


### Calculating a diagonalization

Let $$A$$ be an $$n\times n$$ matrix.
To calculate the diagonalization of $$A$$ we use the following steps.

**Diagonalization Steps**

* (1) Calculate the $$n$$ eigenvalues $$\lambda_1,\dots\lambda_n$$ of $$A$$ (counting multiplicity)
* (2) For each eigenvalue $$\lambda_k$$, calculate an eigenvector of $$\vec v_k$$ of $$A$$ with eigenvalue $$\lambda$$.
* (3) Let $$P$$ be the matrix whose columns are the eigenvectors we found and $$D$$ the diagonal matrix of eigenvalues.

$$P = [\vec v_1\ \vec v_2\ \dots\ \vec v_n],\quad D = \text{diag}(\lambda_1,\lambda_2,\dots,\lambda_n).$$

If $$P$$ is invertible, then $$P$$ and $$D$$ define a diagonalization of $$A$$.

In MATLAB, these steps are all automatically accomplished using the *eig* command:

```Matlab
[P,D] = eig(A);
```

Note that in the algorithm described above, we required that the matrix $$P$$ be invertible.  It can happen that no matter what eigenvectors we choose the matrix $$P$$ will not be invertible.  In such a case, a diagonalization of a matrix does not always exist.  Matrices which do not have a diagonalization are called **degenerate**.  Matrices that have a diagonalization are called **nondegenerate**.

### Diagonalization of symmetric matrices
An important special case of matrices in the context of diagonalization are symmetric matrices.

**Definition:** A real, $$n\times n$$ matrix $$A$$ is called **symmetric** if it is equal to its transpose, ie $$A^T=A$$.

A symmetric matrix is always diagonalizable by a very special matrix called an orthogonal matrix.

**Definition:** A real, $$n\times n$$ matrix $$U$$ is called **orthogonal** or **unitary** if $$U^T=U^{-1}$$.

**Theorem:** Let $$A$$ be a real, symmetric $$n\times n$$ matrix.  Then there exists an orthogonal matrix $$U$$ and a real diagonal matrix $$D$$ satisfying

$$A = PDP^{-1}.$$

In MATLAB, if $$A$$ is a real, symmetric matrix then the *eig* command automatically returns an orthogonal matrix.

### Applications of diagonalization

Diagonalization has a lot of useful properties for matrices, for example in calculating large powers of matrices.
The key observation is that powers behave well with respect to diagonal decompositions.  For example

$$(PDP^{-1})^2 = PDP^{-1}PDP^{-1} = PDIDP^{-1} = PD^2P^{-1}$$

$$(PDP^{-1})^3 = (PDP^{-1})^2PDP^{-1} = PD^2P^{-1}PDP^{-1} = PD^2IDP^{-1} = PD^3P^{-1}$$

In general:

$$(PDP^{-1})^n = PD^nP^{-1},\ \text{for all n>0}.$$

Suppose, for example, we want to calculate  $$A^{100}$$ for

$$A = \left(\begin{array}{cc}1 & 1\\ 0 & 2\end{array}\right).$$

The eigenvalues of $$A$$ are $$1$$ and $$2$$.  The vector $$\binom{1}{0}$$ is an eigenvector with eigenvalue $$1$$ and the vector $$\binom{1}{1}$$ is an eigenvector with eigenvalue $$2$$.  Thus if we take

$$
P = \left(\begin{array}{cc}1 & 1\\ 0 & 1\end{array}\right),\quad
D = \left(\begin{array}{cc}1 & 0\\ 0 & 2\end{array}\right)
$$

then we have $$A = PDP^{-1}.$$  Now if want to calculate $$A^{100}$$, then we simply find

$$
\begin{align*}
A^{100}
  & = (PDP^{-1})^{100} = PD^{100}P^{-1}\\
  & = \left(\begin{array}{cc}1 & 1\\ 0 & 1\end{array}\right)
      \left(\begin{array}{cc}1 & 0\\ 0 & 2^{100}\end{array}\right)
      \left(\begin{array}{cc}1 & -1\\ 0 & 1\end{array}\right)\\
  & = \left(\begin{array}{cc}1 & 1\\ 0 & 1\end{array}\right)
      \left(\begin{array}{cc}1 & -1\\ 0 & 2^{100}\end{array}\right)\\
  & = \left(\begin{array}{cc}1 & 2^{100}-1\\ 0 & 2^{100}\end{array}\right).
\end{align*}
$$


### Fibonacci sequences

The Fibonacci sequence is the sequence $$f_1,f_2,f_3,\dots$$ defined recursively by

$$f_1=1,\ f_2=1,\ f_3=2,\ \dots f_{n+1} = f_{n} + f_{n-1}\ \forall n\geq 2.$$


Thus the first several terms of the Fibonacci sequence are

| $$n$$ | $$f_n$$ |
| ----- | ------- |
|   1   |    1    |
|   2   |    1    |
|   3   |    2    |
|   4   |    3    |
|   5   |    5    |
|   6   |    8    |
|   7   |   13    |
|   8   |   21    |
|   9   |   34    |
|  10   |   55    |

We can use diagonalization to get an explicit formula for the $$n$$'th term $$f_n$$ of the Fibonacci sequence.
We start by noticing that the $$2\times 2$$ matrix

$$A = \left(\begin{array}{cc}0 & 1\\ 1 & 1\end{array}\right)$$

satisfies

$$A\binom{f_{n-1}}{f_n} = \binom{f_n}{f_{n+1}}.$$

Thus for example

$$A\binom{1}{1} = \frac{1}{2}$$

$$A^2\binom{1}{1} = A\binom{1}{2} = \frac{2}{3}$$

$$A^3\binom{1}{1} = A\binom{2}{3} = \frac{3}{5}$$

In general

$$A^n\binom{1}{1} = \binom{f_{n+1}}{f_{n+2}}.$$

Thus to get a closed form solution, we should perform the diagonalization of $$A$$.

The eigenvalues of $$A$$ are roots of the characteristic polynomial polynomial $$x^2-x-1$$, which are $$\gamma_{\pm} = (1\pm\sqrt{5})/2$$.
The value $$\gamma_+$$ is particularly special as it is the well-known **golden ratio**.

An eigenvector with eigenvalue $$\gamma_\pm$$ is $$\binom{\gamma_\pm-1}{1}$$.
Thus if we take

$$
P = \left(\begin{array}{cc}\gamma_+-1 & \gamma_--1\\ 1 & 1\end{array}\right),\quad
D = \left(\begin{array}{cc}\gamma_+ & 0\\ 0 & \gamma_-\end{array}\right)
$$

then we have $$A = PDP^{-1}.$$  Therefore

$$A^n = PD^nP^{-1}$$

Putting this together with our formula above, we find

$$PD^nP^{-1}\binom{1}{1} = \binom{f_{n+1}}{f_{n+2}}.$$

Working out the terms explicitly,

we get

$$f_{n+2} = \frac{2\gamma_+^n-2\gamma_-^n - \gamma_+^n\gamma_- + \gamma_-^n\gamma^+}{\gamma_+-\gamma_-}.$$

For example, for $$n=98$$ this gives the hundredth term in the Fibonacci sequence:

$$f_{100} = 354224848179261915075.$$

## LU Decomposition

Let $$A$$ be an $$n\times n$$ square matrix.
An LU decomposition of $$A$$ is pair of $$n\times n$$ matrices $$L$$ and $$U$$ satisfying

$$A = LU,$$

where here $$L$$ is a **lower triangular matrix**

$$L = \left[\begin{array}{cccc}
\ell_{11} & 0         & \dots   & 0\\
\ell_{21} & \ell_{22} & \dots   & 0\\
\vdots    & \vdots    & \ddots  & \vdots\\
\ell_{31} & \ell_{32} & \dots   & \ell_{nn}
\end{array}\right].$$

and $$U$$ is an **upper triangular matrix**

$$U = \left[\begin{array}{cccc}
u_{11} & u_{12} & \dots   & u_{1n}\\
0      & u_{22} & \dots   & u_{2n}\\
\vdots & \vdots & \ddots  & \vdots\\
0      & 0     & \dots   & u_{nn}
\end{array}\right].$$

A matrix $$A$$ may not have an LU decomposition, or may possibly have many LU decompositions.

### Calculating an LU decomposition

If an LU decomposition of a matrix $$A$$ exists, then necessarily we can find one where the diagonal entries of $$L$$ are all $$1$$, ie. $$\ell_{jj} = 1$$ for all $$j$$.
With this in mind, to find an LU decomposition we can multiply $$L$$ and $$U$$ as defined above together and compare with the coefficients of $$A$$.
Doing so leads to an algorithm for the entries of $$L$$ and $$U$$:

* **initial step 1:** set the first row of $$U$$ by $$u_{1k} = a_{1k}$$ for all $$k$$
* **initial step 2:** set the first column of $$L$$ by $$\ell_{j1} = a_{j1}/u_{11}$$ for all $$j$$
* **general step 3:** given the first $$m-1$$ rows of $$U$$ and the first $$m-1$$ columns of $$L$$, define the $$m$$'th row of $$U$$ by

$$u_{mk} = a_{mk}-\sum_{i=1}^{m-1} \ell_{mi}u_{ik}$$

* **general step 4:** given the first $$m$$ rows of $$U$$ and the first $$m-1$$ columns of $$L$$, define the $$m$$'th column of $$L$$ by

$$\ell_{jm} = \frac{1}{u_{mm}}\left( a_{jm} - \sum_{i=m+1}^j \ell_{ji}u_{im}\right).$$

In MATLAB, we can calculate an LU decomposition of a matrix, if it exists, by using

```MATLAB
[L,U] = lu(A);
```
If the LU decomposition doesn't exist, $$L$$ is returned as a *permuted* lower triangular matrix.

### LU decomposition of symmetric matrices

When $$A$$ is symmetric, we it makes sense to try to find a decomposition which captures the symmetry of the matrix.
Specifically, we look for a special LU decomposition where $$U = L^T$$ and

$$A = LL^T.$$

This kind of decomposition is called a **Cholesky decomposition**.  When all of the eigenvalues of $$A$$ are greater than $$0$$ the matrix $$A$$ is called **positive definite**.  Every positive-definite matrix has a Cholesky decomposition, and the decomposition in this case can be computed more rapidly and with greater numerical stability than in the general situation.

In MATLAB, we can get the Cholesky decomposition via the *chol()* function.

```MATLAB
U = chol(A);
```

This returns an upper triangular matrix, if it exists, satisfying $$A = U^TU$$.


### Applications of LU decompositions.
Linear systems of equations $$T\vec x = \vec b$$ where $$T$$ is a (upper or lower) triangular matrix are easily solved!  One can recursively deduce the value of the solution by eliminating one variable at a time.  In this way, when a matrix has an LU decomposition that we can calculate, the decomposition can be used to easily solve a linear system of equations.
An LU decomposition also allows us to quickly evaluate things like the determinant of the matrix.



## Reading assignments

* <a target="_parent" href="../../../extras/textbook.pdf">primary text (link)</a>: chapter 12 Section 3
* When Life Is Linear: Ch. 7 (14 pages)



