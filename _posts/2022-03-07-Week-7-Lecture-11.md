---
layout: post
---

Notes and highlights from lecture

## Today's Objectives

* Matrix multiplication

## Reading assignments

* <a target="_parent" href="../../../extras/textbook.pdf">primary text (link)</a>: section 8.2

## Dot product

The **dot product** of two vectors $$\vec a$$ and $$\vec b$$ of length $$n$$ is the scalar

$$\vec a\cdot\vec b = \sum_{j=1}^n a_jb_j = a_1b_1 + a_2b_2 + \dots + a_nb_n$$

## Matrix product

We can represent an $$m\times n$$ matrix $$A$$ in a couple other useful ways:
* as a column of row vectors

$$A = \left[\begin{array}{c}\vec r_1\\\vec r_2\\\vdots\\\vec r_m\end{array}\right]$$

* as a row of column vectors

$$A = [\vec c_1\ \vec c_2\ \vec c_3\ \dots\ \vec c_n]$$

With this in mind, for any column vector $$\vec b$$ of length $$n$$, the **matrix product** of $$A$$ and $$B$$ is

$$A\vec b = \left[\begin{array}{c}\vec r_1\cdot\vec b\\ \vec r_2\cdot\vec b\\\vdots\\\vec r_n\cdot\vec b\end{array}\right].$$

**Important:** The number of columns of $$A$$ must be the length of $$\vec b$$.

**special case:** if $$\vec a$$ is a row vector of length $$n$$ (ie. $$1\times n$$ matrix) and $$\vec b$$ is a column vector of length $$n$$

$$\vec a\vec b = \vec a\cdot \vec b$$

## Matrix multiplication

Generaliznig all of the above, we can multiply two matrices together!

Let $$A$$ be a $$m\times n$$ matrix and $$B$$ be a $$n\times \ell$$ matrix.  Then the **matrix product** $$AB$$ is the matrix

$$AB = [A\vec b_1\ \ A\vec b_2\ \ \dots\ \ A\vec b_{\ell}]$$

**Important:** the number of columns of $$A$$ must be the number of rows of $$B$$ for $$AB$$ to make sense

## Properties of matrix multiplication
Let $$A$$,$$B$$,$$C$$, and $$D$$ be matrices of size $$m\times n$$, $$n\times \ell$$, $$n\times \ell$$, and $$\ell\times p$$ respectively.  Then matrix multiplication has the following properties
* distributivity: $$A(B + C) = AB + AC$$ and $$(B+C)D = BD + CD$$
* associativity: $$A(BD) = (AB)D$$
* scalars: $$x(AB) = (xA)B = A(xB)$$

**Important:** if $$AB= AC$$ it is not necessarily true that $$B = C$$

An important special case of matrices are **square matrices**, ie. $$n\times n$$ matrices $$A$$.  If $$A$$ and $$B$$ are both $$n\times n$$ square matrices, then the products $$AB$$ and $$BA$$ make sense but may not be equal.  This is called **noncommutativity**.
In this case we can also consider **matrix powers**

$$A^k = \underbrace{AAA\dots A}_{\text{$k$ times}}$$


## Identity matrix

Recall that the identity matrix of size $$n$$ is the $$n\times n$$ matrix $$I_n$$ with ones on the main diagonal and zeros elsewhere.  It satisfies the property that for any $$m\times n$$ matrix $$A$$

$$I_mA = A = AI_n$$




## Additional resources

**Lecture notes:** <a target="_parent" href="https://wcasper.github.io/math107spring2022/extras/notes/lecture11-2022-03-07.pdf">notes for lecture (link)</a>

**Lecture video:** <a target="_parent" href="https://youtu.be/tOKr63TRuaM">recording of lecture (link)</a>


